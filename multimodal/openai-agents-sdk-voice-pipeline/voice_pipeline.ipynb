{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e3023a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you've followed the base quickstart instructions for the Agents SDK, and set up a virtual environment. Then, install the optional voice dependencies from the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce84bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install 'openai-agents[voice]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489450b4",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "The main concept to know about is a VoicePipeline, which is a 3 step process:\n",
    "\n",
    "    Run a speech-to-text model to turn audio into text.\n",
    "    Run your code, which is usually an agentic workflow, to produce a result.\n",
    "    Run a text-to-speech model to turn the result text back into audio.\n",
    "\n",
    "<img src=\"static/image.png\" alt=\"Description of Image\" width=\"600\"/>\n",
    "\n",
    "## Agents\n",
    "\n",
    "First, let's set up some Agents. This should feel familiar to you if you've built any agents with this SDK. We'll have a couple of Agents, a handoff, and a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "from agents import (\n",
    "    Agent,\n",
    "    function_tool,\n",
    ")\n",
    "from agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n",
    "\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    print(f\"[debug] get_weather called with city: {city}\")\n",
    "    choices = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n",
    "    return f\"The weather in {city} is {random.choice(choices)}.\"\n",
    "\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish\",\n",
    "    handoff_description=\"A spanish speaking agent.\",\n",
    "    instructions=prompt_with_handoff_instructions(\n",
    "        \"You're speaking to a human, so be polite and concise. Speak in Spanish.\",\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=prompt_with_handoff_instructions(\n",
    "        \"You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.\",\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoffs=[spanish_agent],\n",
    "    tools=[get_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b978d5",
   "metadata": {},
   "source": [
    "## Voice pipeline\n",
    "\n",
    "We'll set up a simple voice pipeline, using SingleAgentVoiceWorkflow as the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e60dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.voice import SingleAgentVoiceWorkflow, VoicePipeline\n",
    "pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616d080",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145dfbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from agents.voice import AudioInput\n",
    "\n",
    "# For simplicity, we'll just create 3 seconds of silence\n",
    "# In reality, you'd get microphone data\n",
    "buffer = np.zeros(24000 * 3, dtype=np.int16)\n",
    "audio_input = AudioInput(buffer=buffer)\n",
    "\n",
    "result = await pipeline.run(audio_input)\n",
    "\n",
    "# Create an audio player using `sounddevice`\n",
    "player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)\n",
    "player.start()\n",
    "\n",
    "# Play the audio stream as it comes in\n",
    "async for event in result.stream():\n",
    "    if event.type == \"voice_stream_event_audio\":\n",
    "        player.write(event.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe84ea",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b518c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "from agents import (\n",
    "    Agent,\n",
    "    function_tool,\n",
    "    set_tracing_disabled,\n",
    ")\n",
    "from agents.voice import (\n",
    "    AudioInput,\n",
    "    SingleAgentVoiceWorkflow,\n",
    "    VoicePipeline,\n",
    ")\n",
    "from agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    print(f\"[debug] get_weather called with city: {city}\")\n",
    "    choices = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n",
    "    return f\"The weather in {city} is {random.choice(choices)}.\"\n",
    "\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish\",\n",
    "    handoff_description=\"A spanish speaking agent.\",\n",
    "    instructions=prompt_with_handoff_instructions(\n",
    "        \"You're speaking to a human, so be polite and concise. Speak in Spanish.\",\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=prompt_with_handoff_instructions(\n",
    "        \"You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.\",\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoffs=[spanish_agent],\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))\n",
    "    buffer = np.zeros(24000 * 3, dtype=np.int16)\n",
    "    audio_input = AudioInput(buffer=buffer)\n",
    "\n",
    "    result = await pipeline.run(audio_input)\n",
    "\n",
    "    # Create an audio player using `sounddevice`\n",
    "    player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)\n",
    "    player.start()\n",
    "\n",
    "    # Play the audio stream as it comes in\n",
    "    async for event in result.stream():\n",
    "        if event.type == \"voice_stream_event_audio\":\n",
    "            player.write(event.data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6371ace",
   "metadata": {},
   "source": [
    "If you run this example, the agent will speak to you! Check out the example in [examples/voice/static](https://github.com/openai/openai-agents-python/tree/main/examples/voice/static) to see a demo where you can speak to the agent yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
